{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c1dcda-443a-4575-b2b7-e079d8ffbc75",
   "metadata": {},
   "source": [
    "**Document Classification Case Study** <br>\n",
    "Implement an automated solution using machine learning to classify documents into three categories: Legal, Marketing, and Engineering.\n",
    "\n",
    "**Available Data** <br>\n",
    "A training dataset, training_data.pk, of pre-labeled documents, all in .txt form:\n",
    "- legal documents (contracts, agreements, compliance reports)\n",
    "- marketing documents (brochures, campaign materials, social media content)\n",
    "- engineering documents (technical specifications, code documentation, design docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcacc6e-1620-48b2-80de-732e8797e6f1",
   "metadata": {},
   "source": [
    "**A. Development** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810cde3",
   "metadata": {},
   "source": [
    "**1. Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872248a1-a4e5-412b-885a-aa5997bb1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function(s)\n",
    "def read_pickle(path_in, name_in):\n",
    "    import pickle\n",
    "    the_data_t = pickle.load(open(path_in + name_in + \".pk\", \"rb\"))\n",
    "    return the_data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da858b7-261e-4429-b524-b1fc4323d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data set \n",
    "file_path =  \".../data/\"\n",
    "docs_cat = read_pickle(file_path, \"training_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7edf4c-d0bd-4f08-8d15-552b53bcbc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We use essential cookies to make Venngage wor...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A legal contract is a written document that is...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>November 27 2023 14 min Author Olga Asheychik...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accelerate contracts with AI native workflows ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create smarter agreements commit to them more ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Clearly defined requirements are essential sig...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>I P b1 Xz Y 8 2 gQR D m Ң B W 18YO h ѱ t v1 o...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Become a CSI Certified Professional Prove you...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>This is a series of short articles as an overv...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>We use cookies to ensure we give you the best ...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0     We use essential cookies to make Venngage wor...   \n",
       "1    A legal contract is a written document that is...   \n",
       "2     November 27 2023 14 min Author Olga Asheychik...   \n",
       "3    Accelerate contracts with AI native workflows ...   \n",
       "4    Create smarter agreements commit to them more ...   \n",
       "..                                                 ...   \n",
       "219  Clearly defined requirements are essential sig...   \n",
       "220   I P b1 Xz Y 8 2 gQR D m Ң B W 18YO h ѱ t v1 o...   \n",
       "221   Become a CSI Certified Professional Prove you...   \n",
       "222  This is a series of short articles as an overv...   \n",
       "223  We use cookies to ensure we give you the best ...   \n",
       "\n",
       "                                  label  \n",
       "0               legal_contract_examples  \n",
       "1               legal_contract_examples  \n",
       "2               legal_contract_examples  \n",
       "3               legal_contract_examples  \n",
       "4               legal_contract_examples  \n",
       "..                                  ...  \n",
       "219  engineering_specification_examples  \n",
       "220  engineering_specification_examples  \n",
       "221  engineering_specification_examples  \n",
       "222  engineering_specification_examples  \n",
       "223  engineering_specification_examples  \n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View data set \n",
    "docs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e500276-b4b5-4f22-b000-eeb3377eff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['legal_contract_examples', 'marketing_material_examples',\n",
       "       'engineering_specification_examples'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique labels\n",
    "docs_cat['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a04d54a",
   "metadata": {},
   "source": [
    "**2. Data preparation**\n",
    "*including clean text, stop words removal and stemming* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a34127c-dc1e-4a57-b25c-a99feb95cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function(s)\n",
    "## Clean text \n",
    "def clean_txt(var_in):\n",
    "    import re\n",
    "    tmp_t = re.sub(\"[^A-Za-z']+\", \" \", var_in\n",
    "                   ).strip().lower()\n",
    "    return tmp_t\n",
    "\n",
    "## Remove stop words\n",
    "def rem_sw(str_in):\n",
    "    from nltk.corpus import stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    tmp = [word for word in str_in.split() if word not in sw]\n",
    "    tmp = ' '.join(tmp)\n",
    "    return tmp\n",
    "\n",
    "## Stemming \n",
    "def stem_fun(var_in, sw_in):\n",
    "    if sw_in == \"stem\":\n",
    "        from nltk.stem import PorterStemmer\n",
    "        ps = PorterStemmer()\n",
    "    else:\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        ps = WordNetLemmatizer()\n",
    "    split_ex = var_in.split()\n",
    "    t_l = list()\n",
    "    for word in split_ex:\n",
    "        if sw_in == \"stem\":\n",
    "            tmp = ps.stem(word)\n",
    "        else:\n",
    "            tmp = ps.lemmatize(word)\n",
    "        t_l.append(tmp)\n",
    "    tmp = ' '.join(t_l)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb8f7b6-8188-41c8-a5f9-7b642d2aa45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we use essential cookies to make venngage work...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a legal contract is a written document that is...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>november min author olga asheychik senior web ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accelerate contracts with ai native workflows ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create smarter agreements commit to them more ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>clearly defined requirements are essential sig...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>i p b xz y gqr d m b w yo h t v o tt as l k qs...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>become a csi certified professional prove your...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>this is a series of short articles as an overv...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>we use cookies to ensure we give you the best ...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    we use essential cookies to make venngage work...   \n",
       "1    a legal contract is a written document that is...   \n",
       "2    november min author olga asheychik senior web ...   \n",
       "3    accelerate contracts with ai native workflows ...   \n",
       "4    create smarter agreements commit to them more ...   \n",
       "..                                                 ...   \n",
       "219  clearly defined requirements are essential sig...   \n",
       "220  i p b xz y gqr d m b w yo h t v o tt as l k qs...   \n",
       "221  become a csi certified professional prove your...   \n",
       "222  this is a series of short articles as an overv...   \n",
       "223  we use cookies to ensure we give you the best ...   \n",
       "\n",
       "                                  label  \n",
       "0               legal_contract_examples  \n",
       "1               legal_contract_examples  \n",
       "2               legal_contract_examples  \n",
       "3               legal_contract_examples  \n",
       "4               legal_contract_examples  \n",
       "..                                  ...  \n",
       "219  engineering_specification_examples  \n",
       "220  engineering_specification_examples  \n",
       "221  engineering_specification_examples  \n",
       "222  engineering_specification_examples  \n",
       "223  engineering_specification_examples  \n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the corpus \n",
    "docs_cat['body'] = docs_cat['body'].apply(clean_txt)\n",
    "docs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a90720-944a-490c-953f-d69796ad9f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>body_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we use essential cookies to make venngage work...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>use essential cookies make venngage work click...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a legal contract is a written document that is...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>legal contract written document drawn party ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>november min author olga asheychik senior web ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>november min author olga asheychik senior web ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accelerate contracts with ai native workflows ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>accelerate contracts ai native workflows advan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create smarter agreements commit to them more ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>create smarter agreements commit efficiently m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>clearly defined requirements are essential sig...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>clearly defined requirements essential signs r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>i p b xz y gqr d m b w yo h t v o tt as l k qs...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>p b xz gqr b w yo h v tt l k qs qck w hj u ht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>become a csi certified professional prove your...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>become csi certified professional prove expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>this is a series of short articles as an overv...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>series short articles overview simple guide ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>we use cookies to ensure we give you the best ...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>use cookies ensure give best experience websit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    we use essential cookies to make venngage work...   \n",
       "1    a legal contract is a written document that is...   \n",
       "2    november min author olga asheychik senior web ...   \n",
       "3    accelerate contracts with ai native workflows ...   \n",
       "4    create smarter agreements commit to them more ...   \n",
       "..                                                 ...   \n",
       "219  clearly defined requirements are essential sig...   \n",
       "220  i p b xz y gqr d m b w yo h t v o tt as l k qs...   \n",
       "221  become a csi certified professional prove your...   \n",
       "222  this is a series of short articles as an overv...   \n",
       "223  we use cookies to ensure we give you the best ...   \n",
       "\n",
       "                                  label  \\\n",
       "0               legal_contract_examples   \n",
       "1               legal_contract_examples   \n",
       "2               legal_contract_examples   \n",
       "3               legal_contract_examples   \n",
       "4               legal_contract_examples   \n",
       "..                                  ...   \n",
       "219  engineering_specification_examples   \n",
       "220  engineering_specification_examples   \n",
       "221  engineering_specification_examples   \n",
       "222  engineering_specification_examples   \n",
       "223  engineering_specification_examples   \n",
       "\n",
       "                                               body_sw  \n",
       "0    use essential cookies make venngage work click...  \n",
       "1    legal contract written document drawn party ag...  \n",
       "2    november min author olga asheychik senior web ...  \n",
       "3    accelerate contracts ai native workflows advan...  \n",
       "4    create smarter agreements commit efficiently m...  \n",
       "..                                                 ...  \n",
       "219  clearly defined requirements essential signs r...  \n",
       "220  p b xz gqr b w yo h v tt l k qs qck w hj u ht ...  \n",
       "221  become csi certified professional prove expert...  \n",
       "222  series short articles overview simple guide ne...  \n",
       "223  use cookies ensure give best experience websit...  \n",
       "\n",
       "[224 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words in the corpus \n",
    "docs_cat['body_sw'] = docs_cat['body'].apply(rem_sw)\n",
    "docs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b614fb-990e-4681-acd1-0139cfdcc109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>body_sw</th>\n",
       "      <th>body_sw_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we use essential cookies to make venngage work...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>use essential cookies make venngage work click...</td>\n",
       "      <td>we use essenti cooki to make venngag work by c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a legal contract is a written document that is...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>legal contract written document drawn party ag...</td>\n",
       "      <td>a legal contract is a written document that is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>november min author olga asheychik senior web ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>november min author olga asheychik senior web ...</td>\n",
       "      <td>novemb min author olga asheychik senior web an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accelerate contracts with ai native workflows ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>accelerate contracts ai native workflows advan...</td>\n",
       "      <td>acceler contract with ai nativ workflow advanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create smarter agreements commit to them more ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>create smarter agreements commit efficiently m...</td>\n",
       "      <td>creat smarter agreement commit to them more ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>clearly defined requirements are essential sig...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>clearly defined requirements essential signs r...</td>\n",
       "      <td>clearli defin requir are essenti sign on the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>i p b xz y gqr d m b w yo h t v o tt as l k qs...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>p b xz gqr b w yo h v tt l k qs qck w hj u ht ...</td>\n",
       "      <td>i p b xz y gqr d m b w yo h t v o tt as l k qs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>become a csi certified professional prove your...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>become csi certified professional prove expert...</td>\n",
       "      <td>becom a csi certifi profession prove your expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>this is a series of short articles as an overv...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>series short articles overview simple guide ne...</td>\n",
       "      <td>thi is a seri of short articl as an overview a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>we use cookies to ensure we give you the best ...</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>use cookies ensure give best experience websit...</td>\n",
       "      <td>we use cooki to ensur we give you the best exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    we use essential cookies to make venngage work...   \n",
       "1    a legal contract is a written document that is...   \n",
       "2    november min author olga asheychik senior web ...   \n",
       "3    accelerate contracts with ai native workflows ...   \n",
       "4    create smarter agreements commit to them more ...   \n",
       "..                                                 ...   \n",
       "219  clearly defined requirements are essential sig...   \n",
       "220  i p b xz y gqr d m b w yo h t v o tt as l k qs...   \n",
       "221  become a csi certified professional prove your...   \n",
       "222  this is a series of short articles as an overv...   \n",
       "223  we use cookies to ensure we give you the best ...   \n",
       "\n",
       "                                  label  \\\n",
       "0               legal_contract_examples   \n",
       "1               legal_contract_examples   \n",
       "2               legal_contract_examples   \n",
       "3               legal_contract_examples   \n",
       "4               legal_contract_examples   \n",
       "..                                  ...   \n",
       "219  engineering_specification_examples   \n",
       "220  engineering_specification_examples   \n",
       "221  engineering_specification_examples   \n",
       "222  engineering_specification_examples   \n",
       "223  engineering_specification_examples   \n",
       "\n",
       "                                               body_sw  \\\n",
       "0    use essential cookies make venngage work click...   \n",
       "1    legal contract written document drawn party ag...   \n",
       "2    november min author olga asheychik senior web ...   \n",
       "3    accelerate contracts ai native workflows advan...   \n",
       "4    create smarter agreements commit efficiently m...   \n",
       "..                                                 ...   \n",
       "219  clearly defined requirements essential signs r...   \n",
       "220  p b xz gqr b w yo h v tt l k qs qck w hj u ht ...   \n",
       "221  become csi certified professional prove expert...   \n",
       "222  series short articles overview simple guide ne...   \n",
       "223  use cookies ensure give best experience websit...   \n",
       "\n",
       "                                          body_sw_stem  \n",
       "0    we use essenti cooki to make venngag work by c...  \n",
       "1    a legal contract is a written document that is...  \n",
       "2    novemb min author olga asheychik senior web an...  \n",
       "3    acceler contract with ai nativ workflow advanc...  \n",
       "4    creat smarter agreement commit to them more ef...  \n",
       "..                                                 ...  \n",
       "219  clearli defin requir are essenti sign on the r...  \n",
       "220  i p b xz y gqr d m b w yo h t v o tt as l k qs...  \n",
       "221  becom a csi certifi profession prove your expe...  \n",
       "222  thi is a seri of short articl as an overview a...  \n",
       "223  we use cooki to ensur we give you the best exp...  \n",
       "\n",
       "[224 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming corpus\n",
    "docs_cat['body_sw_stem'] = docs_cat['body'].apply(lambda x: stem_fun(x, \"stem\"))\n",
    "docs_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12905973",
   "metadata": {},
   "source": [
    "**3. Vectorize the corpus - tf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4c48f1-7c12-4dea-a902-699aa96504a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function(s)\n",
    "## Save the corpus vecterized file(s) for development \n",
    "def write_pickle(obj_in, path_in, name_in):\n",
    "    import pickle\n",
    "    pickle.dump(obj_in, open(path_in + name_in + \".pk\", \"wb\"))\n",
    "\n",
    "## Vectorize the corpus\n",
    "def xform_fun(df_in, m_in, n_in, sw_in, path_in):\n",
    "    import pandas as pd\n",
    "    if sw_in == \"tf\":\n",
    "        from sklearn.feature_extraction.text import CountVectorizer \n",
    "        cv = CountVectorizer(ngram_range=(m_in, n_in))\n",
    "    else:\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        cv = TfidfVectorizer(ngram_range=(m_in, n_in), use_idf=False)\n",
    "    x_f_data_t = pd.DataFrame(\n",
    "        cv.fit_transform(df_in).toarray()) \n",
    "    write_pickle(cv, path_in, sw_in)\n",
    "    x_f_data_t.columns = cv.get_feature_names_out()\n",
    "    return x_f_data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a2b8c1-b0c4-4bec-af9e-2f22479934b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa aa</th>\n",
       "      <th>aa aa gz</th>\n",
       "      <th>aa aa lx</th>\n",
       "      <th>aa ac</th>\n",
       "      <th>aa ac wo</th>\n",
       "      <th>aa ae</th>\n",
       "      <th>aa ae hd</th>\n",
       "      <th>aa am</th>\n",
       "      <th>aa am je</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzj ryr sv</th>\n",
       "      <th>zzzk</th>\n",
       "      <th>zzzk ii</th>\n",
       "      <th>zzzk ii sq</th>\n",
       "      <th>zzzm</th>\n",
       "      <th>zzzm kkk</th>\n",
       "      <th>zzzm kkk xl</th>\n",
       "      <th>zzzrrr</th>\n",
       "      <th>zzzrrr eee</th>\n",
       "      <th>zzzrrr eee xlss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 692814 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aa  aa aa  aa aa gz  aa aa lx  aa ac  aa ac wo  aa ae  aa ae hd  aa am  \\\n",
       "0     0      0         0         0      0         0      0         0      0   \n",
       "1     0      0         0         0      0         0      0         0      0   \n",
       "2     0      0         0         0      0         0      0         0      0   \n",
       "3     0      0         0         0      0         0      0         0      0   \n",
       "4     0      0         0         0      0         0      0         0      0   \n",
       "..   ..    ...       ...       ...    ...       ...    ...       ...    ...   \n",
       "219   0      0         0         0      0         0      0         0      0   \n",
       "220  84      2         1         1      0         0      1         1      0   \n",
       "221   0      0         0         0      0         0      0         0      0   \n",
       "222   0      0         0         0      0         0      0         0      0   \n",
       "223   0      0         0         0      0         0      0         0      0   \n",
       "\n",
       "     aa am je  ...  zzzj ryr sv  zzzk  zzzk ii  zzzk ii sq  zzzm  zzzm kkk  \\\n",
       "0           0  ...            0     0        0           0     0         0   \n",
       "1           0  ...            0     0        0           0     0         0   \n",
       "2           0  ...            0     0        0           0     0         0   \n",
       "3           0  ...            0     0        0           0     0         0   \n",
       "4           0  ...            0     0        0           0     0         0   \n",
       "..        ...  ...          ...   ...      ...         ...   ...       ...   \n",
       "219         0  ...            0     0        0           0     0         0   \n",
       "220         0  ...            0     0        0           0     0         0   \n",
       "221         0  ...            0     0        0           0     0         0   \n",
       "222         0  ...            0     0        0           0     0         0   \n",
       "223         0  ...            0     0        0           0     0         0   \n",
       "\n",
       "     zzzm kkk xl  zzzrrr  zzzrrr eee  zzzrrr eee xlss  \n",
       "0              0       0           0                0  \n",
       "1              0       0           0                0  \n",
       "2              0       0           0                0  \n",
       "3              0       0           0                0  \n",
       "4              0       0           0                0  \n",
       "..           ...     ...         ...              ...  \n",
       "219            0       0           0                0  \n",
       "220            0       0           0                0  \n",
       "221            0       0           0                0  \n",
       "222            0       0           0                0  \n",
       "223            0       0           0                0  \n",
       "\n",
       "[224 rows x 692814 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process\n",
    "output_path = \".../output\"\n",
    "t_form_data = xform_fun(docs_cat[\"body_sw_stem\"], 1, 3, \"tf\", output_path)\n",
    "t_form_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0bbc62",
   "metadata": {},
   "source": [
    "**4. Feature Selections - Chi2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d00b30-511e-44c8-a946-dcea0bb33f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function(s)\n",
    "def chi_fun(df_in, lab_in, k_in, p_in, n_in, stat_sig):\n",
    "    from sklearn.feature_selection import chi2, SelectKBest\n",
    "    import pandas as pd\n",
    "    feat_sel = SelectKBest(score_func=chi2, k=k_in)\n",
    "    dim_data = pd.DataFrame(feat_sel.fit_transform(df_in, lab_in))\n",
    "    p_val = pd.DataFrame(list(feat_sel.pvalues_))\n",
    "    p_val.columns = [\"pval\"]\n",
    "    feat_index = list(p_val[p_val.pval <= stat_sig].index)\n",
    "    dim_data = dim_data[feat_index]\n",
    "    feature_names = df_in.columns[feat_index]\n",
    "    dim_data.columns = feature_names\n",
    "    write_pickle(feat_sel, p_in, n_in)\n",
    "    write_pickle(dim_data, p_in, \"chi_data_\" + n_in)\n",
    "    return dim_data, feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93bee728-b4db-4f15-83f8-393e5b02678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aan</th>\n",
       "      <th>aashto</th>\n",
       "      <th>ab</th>\n",
       "      <th>ab dd</th>\n",
       "      <th>ab ded</th>\n",
       "      <th>ab ded ab</th>\n",
       "      <th>ab initio</th>\n",
       "      <th>ab xmpmm</th>\n",
       "      <th>...</th>\n",
       "      <th>zwe</th>\n",
       "      <th>zx</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyr</th>\n",
       "      <th>zyr ei</th>\n",
       "      <th>zyr ei zyr</th>\n",
       "      <th>zyx</th>\n",
       "      <th>zyy</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 25732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aa  aaa  aan  aashto  ab  ab dd  ab ded  ab ded ab  ab initio  ab xmpmm  \\\n",
       "0     0    0    0       0   0      0       0          0          0         0   \n",
       "1     0    0    0       0   0      0       0          0          0         0   \n",
       "2     0    0    0       0   0      0       0          0          0         0   \n",
       "3     0    0    0       0   0      0       0          0          0         0   \n",
       "4     0    0    0       0   0      0       0          0          0         0   \n",
       "..   ..  ...  ...     ...  ..    ...     ...        ...        ...       ...   \n",
       "219   0    0    0       0   0      0       0          0          0         0   \n",
       "220  84    0    2       0  59      4       0          0          0         0   \n",
       "221   0    0    0       0   0      0       0          0          0         0   \n",
       "222   0    0    0       0   0      0       0          0          0         0   \n",
       "223   0    0    0       0   0      0       0          0          0         0   \n",
       "\n",
       "     ...  zwe  zx  zy  zyr  zyr ei  zyr ei zyr  zyx  zyy  zz  zzz  \n",
       "0    ...    0   0   0    0       0           0    0    0   0    0  \n",
       "1    ...    0   0   0    0       0           0    0    0   0    0  \n",
       "2    ...    0   0   0    0       0           0    0    0   0    0  \n",
       "3    ...    0   0   0    0       0           0    0    0   0    0  \n",
       "4    ...    0   0   0    0       0           0    0    0   0    0  \n",
       "..   ...  ...  ..  ..  ...     ...         ...  ...  ...  ..  ...  \n",
       "219  ...    0   0   0    0       0           0    0    0   0    0  \n",
       "220  ...    4  74  92    6       5           4    4    0  92    1  \n",
       "221  ...    0   0   0    0       0           0    0    0   0    0  \n",
       "222  ...    0   0   0    0       0           0    0    0   0    0  \n",
       "223  ...    0   0   0    0       0           0    0    0   0    0  \n",
       "\n",
       "[224 rows x 25732 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process\n",
    "chi_data, chi_m = chi_fun(t_form_data, docs_cat.label,\n",
    "                      len(t_form_data.columns), output_path, \"chi\", 0.05) \n",
    "chi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83c9f3",
   "metadata": {},
   "source": [
    "**5. Fit model - Random Forest / Gaussian Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9203625-aa3c-41ac-9d99-4e2bda381c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion(s)\n",
    "\n",
    "def model_fun(df_in, lab_in, g_in, t_s, sw_in, p_o):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_in, lab_in, test_size=t_s, random_state=42)\n",
    "    \n",
    "    if sw_in == \"rf\":\n",
    "        model = RandomForestClassifier(random_state=123)\n",
    "    elif sw_in == \"gnb\":\n",
    "        model = GaussianNB()\n",
    "    \n",
    "    clf = GridSearchCV(model, g_in)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_perf = clf.best_score_\n",
    "    print (best_perf)\n",
    "    best_params = clf.best_params_\n",
    "    print (best_params)\n",
    "    \n",
    "    if sw_in == \"rf\":\n",
    "        model = RandomForestClassifier(random_state=123, **best_params)\n",
    "    elif sw_in == \"gnb\":\n",
    "        model = GaussianNB(**best_params)\n",
    "    \n",
    "    X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(\n",
    "        X_test, y_test, test_size=0.10, random_state=42)\n",
    "    \n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    write_pickle(model, p_o, sw_in)\n",
    "    y_pred = model.predict(X_test_val)\n",
    "    y_pred_likelihood = pd.DataFrame(\n",
    "        model.predict_proba(X_test_val))\n",
    "    y_pred_likelihood.columns = model.classes_\n",
    "    \n",
    "    metrics = pd.DataFrame(precision_recall_fscore_support(\n",
    "        y_test_val, y_pred, average='weighted'))\n",
    "    metrics.index = [\"precision\", \"recall\", \"fscore\", None]\n",
    "    \n",
    "    #feature importance\n",
    "    try:\n",
    "        feat_imp = pd.DataFrame(model.feature_importances_)\n",
    "        feat_imp.index = X_train_val.columns\n",
    "        feat_imp.columns = [\"score\"]\n",
    "        feat_imp.to_csv(p_o + sw_in + \"_m.csv\")\n",
    "        perc_prop = len(feat_imp[feat_imp[\"score\"] > 0]) / len(feat_imp) * 100\n",
    "        print (perc_prop)\n",
    "    except:\n",
    "        print (\"Not transparent\")\n",
    "        pass\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ca9a4b-571a-40c8-8b94-34d532e91e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166666666666667\n",
      "{'max_depth': None, 'n_estimators': 50}\n",
      "4.154360329550754\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "sw = \"rf\"\n",
    "parameters = {\"n_estimators\": [50, 100], \"max_depth\": [None, 10]}\n",
    "rf_mod = model_fun(chi_data, docs_cat.label, parameters, 0.80, sw, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff41ee4d",
   "metadata": {},
   "source": [
    "**B. Automation Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2f1b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function(s)\n",
    "def pred_doc_cat(doc, vec_in, chi_in, m_in, stat_sig):\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Preprocess the document\n",
    "    doc = clean_txt(doc)\n",
    "    doc = rem_sw(doc)\n",
    "    doc = stem_fun(doc, \"stem\")\n",
    "    \n",
    "    # Transform text using vectorizer\n",
    "    doc_vec = pd.DataFrame(vec_in.transform([doc]).toarray())\n",
    "    doc_vec.columns = vec_in.get_feature_names_out()\n",
    "    \n",
    "    # Perform Chi-Squared transformation\n",
    "    p_val = pd.DataFrame(list(chi_in.pvalues_))\n",
    "    p_val.columns = [\"pval\"]\n",
    "    feat_index = list(p_val[p_val.pval <= stat_sig].index)\n",
    "    doc_vec = doc_vec.iloc[:, feat_index]  # Select significant features\n",
    "    \n",
    "    # Align features with the trained model\n",
    "    aligned_tmp_chi = pd.DataFrame(0, columns=m_in.feature_names_in_, index=doc_vec.index)\n",
    "    aligned_tmp_chi[doc_vec.columns] = doc_vec\n",
    "    \n",
    "    # Make predictions\n",
    "    pred = m_in.predict(aligned_tmp_chi)[0]\n",
    "    pred_proba = pd.DataFrame(m_in.predict_proba(aligned_tmp_chi))\n",
    "    pred_proba.columns = m_in.classes_\n",
    "    \n",
    "    return pred, pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf801f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required parameters for automation script for predictions predict_doc_category\n",
    "vec_tmp = read_pickle(output_path, \"tf\")\n",
    "chi_tmp = read_pickle(output_path, \"chi\")\n",
    "rf_mod_test = read_pickle(output_path, \"rf\")\n",
    "stat_sig=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce6885",
   "metadata": {},
   "source": [
    "**C. Test Case** <br>\n",
    "*In this test case, the documents to be classified are those related to the topic of \"machine learning\" in .txt format. The model will be considered acceptable if these documents are successfully categorized as \"engineering_specification_examples.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "111ad27b-1eb8-4164-9a39-f0bdb67285e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function(s)\n",
    "def clean_text(var_in):\n",
    "    import re \n",
    "    tmp_t = re.sub(\"[^A-Za-z']+\", \" \", var_in).strip().lower()\n",
    "    return tmp_t\n",
    "    \n",
    "def read_file(full_path_in):\n",
    "    f_t = open(full_path_in, \"r\", encoding = \"UTF-8\", errors=\"ignore\")\n",
    "    text_t = f_t.read() #read the whole file\n",
    "    text_t = clean_text(text_t)\n",
    "    f_t.close()\n",
    "    return text_t \n",
    "\n",
    "def file_crawler(path_in):\n",
    "    import os\n",
    "    import pandas as pd \n",
    "    my_pd_t = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(path_in, topdown = False):\n",
    "        for name in files:\n",
    "            try:\n",
    "                txt_t = read_file(root + \"/\" + name)\n",
    "                if len(txt_t) > 0:\n",
    "                    file_name = root.split(\"/\")[-1]\n",
    "                    tmp_pd = pd.DataFrame(\n",
    "                        {\"body\": txt_t, \"file name\": file_name}, index = [0])\n",
    "                    my_pd_t = pd.concat(\n",
    "                        [my_pd_t, tmp_pd], ignore_index = True)\n",
    "            except: \n",
    "                print(root + \"/\" + name)\n",
    "                pass \n",
    "    return my_pd_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec56aaa-be30-4eda-8edf-20e01626214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process \n",
    "path_test = \".../test_data/\" # input the file path \n",
    "docs_to_cat = file_crawler(path_test)\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "for index, doc in docs_to_cat[\"body\"].items():\n",
    "    pred, pred_proba = pred_doc_cat(doc, vec_tmp, chi_tmp, rf_mod_test, stat_sig)\n",
    "    predictions.append(pred)\n",
    "    probabilities.append(pred_proba.max(axis=1).iloc[0])  \n",
    "    \n",
    "docs_to_cat[\"prediction\"] = predictions\n",
    "docs_to_cat[\"probability\"] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a2455f6-2054-4616-adec-adad0c4ae93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>file name</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine learning search toggle current home ou...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.392048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category machine learning videolectures net ho...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.418381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the algorithms machine learning engineers need...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.378714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is machine learning definition from whati...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.553333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine learning video library learning from d...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.402048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>getting started with machine learning and pred...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>machine learning quora submit any pending chan...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>machine learning ted com menu ideas worth spre...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.373714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>reviews for machine learning from coursera cla...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>engineering_specification_examples</td>\n",
       "      <td>0.560381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>bud i n e l e a m a c h i n e l e a r n i n gi...</td>\n",
       "      <td></td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>0.386429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body        file name  \\\n",
       "0   machine learning search toggle current home ou...  machinelearning   \n",
       "1   category machine learning videolectures net ho...  machinelearning   \n",
       "2   the algorithms machine learning engineers need...  machinelearning   \n",
       "3   what is machine learning definition from whati...  machinelearning   \n",
       "4   machine learning video library learning from d...  machinelearning   \n",
       "..                                                ...              ...   \n",
       "65  getting started with machine learning and pred...  machinelearning   \n",
       "66  machine learning quora submit any pending chan...  machinelearning   \n",
       "67  machine learning ted com menu ideas worth spre...  machinelearning   \n",
       "68  reviews for machine learning from coursera cla...  machinelearning   \n",
       "69  bud i n e l e a m a c h i n e l e a r n i n gi...                    \n",
       "\n",
       "                            prediction  probability  \n",
       "0   engineering_specification_examples     0.392048  \n",
       "1   engineering_specification_examples     0.418381  \n",
       "2   engineering_specification_examples     0.378714  \n",
       "3   engineering_specification_examples     0.553333  \n",
       "4   engineering_specification_examples     0.402048  \n",
       "..                                 ...          ...  \n",
       "65  engineering_specification_examples     0.415000  \n",
       "66  engineering_specification_examples     0.505000  \n",
       "67  engineering_specification_examples     0.373714  \n",
       "68  engineering_specification_examples     0.560381  \n",
       "69             legal_contract_examples     0.386429  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results\n",
    "docs_to_cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
